{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "serious-stanford",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# Data Discovery: Collect HLS links with specifc Bands\n",
    "All instructions are running on crycloud. See README file for setting up enviornment and runnig at local computer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "altered-lucas",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-crawford",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-arthritis",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pystac_client import Client       # https://pystac-client.readthedocs.io/en/latest/index.html  \n",
    "from collections import defaultdict    \n",
    "import json\n",
    "import geopandas\n",
    "import geoviews as gv\n",
    "from cartopy import crs\n",
    "gv.extension('bokeh', 'matplotlib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6162ca89-5899-4a41-99a7-e13f0c7f5658",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### Submit `GET` request to the CMR STAC API\n",
    "\n",
    "Use the `reqests` package to submit a `GET` request to the CMR STAC API. We'll parse the response and extract the information we need to navigate the STAC Catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bf762e-a9db-4efe-ae22-b5c3180bcbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stac_url = 'https://cmr.earthdata.nasa.gov/stac'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1589df27-c851-451a-9f31-56b772c6a532",
   "metadata": {},
   "outputs": [],
   "source": [
    "provider_cat = requests.get(stac_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc30baa-3068-4885-8fb1-b94af3ebf143",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "The CMR STAC API endpoint lists the available providers. Each **provider** is a seperate STAC Catalog endpoint that can be used to submit spatiotemporal queries agaist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bba091-fac5-43cb-abdc-69bbcaeebd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "providers = [p['title'] for p in provider_cat.json()['links'] if 'child' in p['rel']]\n",
    "providers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0403d3e7-64ae-4e75-a53e-de6c7204083a",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### Explore the `LPCLOUD` provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5dc819-89f7-408f-8ab7-c35cd7103e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "provider = 'LPCLOUD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aed3b74-fc0f-4519-8e07-c0c2fe1f2c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "provider_url = f'{stac_url}/{provider}'\n",
    "provider_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8589e46-e7da-4d27-9554-d474f7f0192b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat = requests.get(provider_url)\n",
    "cat.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67e44c8-d270-4724-8aaf-a6d2f17ea3b7",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### List the STAC Collections within the `LPCLOUD` Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e639c1de-1fd9-4bf3-ad36-430cdeffd0c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = [{l['href'].split('/')[-1]: l['href']} for l in cat.json() ['links'] if 'child' in l['rel']]\n",
    "for c in cols:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a517eb-e7fd-44c2-b9fd-e6f35d81e46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(f\"Requesting page:\")\n",
    "    while nxt_pg := [l for l in cat.json()['links'] if 'next' in l['rel']][0]:\n",
    "        print(f\"{nxt_pg['href'].split('=')[-1]}...\", end = ' ')\n",
    "        cat = requests.get(nxt_pg['href'])\n",
    "        cols.extend([{l['href'].split('/')[-1]: l['href']} for l in cat.json()['links']if 'child' in l['rel']])\n",
    "except:\n",
    "    print('No additional pages')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420a85ff-f60d-4bdb-a54d-5564962a60f5",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### Print all available STAC Collections within the `LPCLOUD` Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d1295b-d620-4702-8786-b5025071b5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'LPCLOUD has {len(cols)} Collections')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9cdd05-6350-4790-95e5-38dd050ac3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cols:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cfa860-010f-4c3b-8689-6544db7fd063",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### Get information about an individual Collection\n",
    "\n",
    "Below we'll specify a STAC Collection, `HLSL30.v2.0`, and request the STAC metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9806342a-5959-492a-9c12-1b48315a91dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = 'HLSL30.v2.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4630ed-c622-4463-8431-ae363c4eb0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_link = list(filter(lambda c: collection == list(c.keys())[0], cols))[0]\n",
    "collection_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58c4b49-72d2-42d1-8b6d-c879deaa7435",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.get(collection_link[collection]).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-tournament",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### Set up query parameters to submit to the CMR-STAC API\n",
    "\n",
    "For this next sections we'll use a Python package call `pystac_client` to submit a spatiotemporal querie for data assets across multiple Collections. We will define our area of interest using the geojson file from the previous exercise, while also specifying the data collections and time range of needed for our example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-mixture",
   "metadata": {},
   "outputs": [],
   "source": [
    "field = geopandas.read_file('../data/ne_w_agfields.geojson')\n",
    "field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-corpus",
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldShape = field['geometry'][0]\n",
    "fieldShape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-event",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = gv.tile_sources.EsriImagery.opts(width=650, height=500)\n",
    "farmField = gv.Polygons(fieldShape).opts(line_color='yellow', line_width=10, color=None)\n",
    "base * farmField"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-gossip",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "We will now start to specify the search criteria we are interested in, i.e, the **date range**, the **region of interest** (roi), and the **data collections**, to pass to the STAC API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mobile-arnold",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "#### Specify the region of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-breathing",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = json.loads(field.to_json())['features'][0]['geometry']\n",
    "print(roi)\n",
    "roi_pt = json.loads('{\"type\":\"Point\", \"coordinates\":[-119.256, 37.901]}') # Dana meadow\n",
    "print(roi_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informal-introduction",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "#### Specify date range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-russell",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = \"2019-07/2019-08\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-security",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "#### Specify the STAC Collections\n",
    "\n",
    "**Note,** a STAC Collection is synonomous with what we usually consider a data product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-copying",
   "metadata": {},
   "outputs": [],
   "source": [
    "collections = ['HLSL30.v2.0', 'HLSS30.v2.0']\n",
    "collections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proper-generic",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### Perform Search Against the CMR-STAC API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee17694e-1b02-45ab-9b79-c077c6614d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = Client.open(provider_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-prairie",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = catalog.search(\n",
    "    collections=collections,\n",
    "    intersects=roi_pt,\n",
    "    datetime=date_range\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-pastor",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "#### Print out how many STAC Items match our search query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-blair",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.matched()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "through-whole",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "We now have a search object containing the STAC records that matched our query. Now, let's pull out all of the STAC Items (as a PySTAC ItemCollection object) and explore the contents (i.e., the STAC Items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-shelf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "item_collection = list(search.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-rolling",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-enemy",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "#### Grab the first Item and print it out as a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-eligibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_collection[2].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-facility",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### Filtering STAC Items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-desire",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "Now we will set the max cloud cover allowable and extract the band links for those Items that match or are less than the max cloud cover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-passing",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloudcover = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hidden-nothing",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "We will also specify the STAC Assets (i.e., bands/layers) of interest for both the S30 and L30 collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-convert",
   "metadata": {},
   "outputs": [],
   "source": [
    "s30_bands = ['B02', 'B04']\n",
    "l30_bands = ['B02', 'B04']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-letters",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evi_band_links = []\n",
    "\n",
    "for i in item_collection:\n",
    "    if i.properties['eo:cloud_cover'] <= cloudcover:\n",
    "        if i.collection_id == 'HLSS30.v2.0':\n",
    "            #print(i.properties['eo:cloud_cover'])\n",
    "            evi_bands = s30_bands\n",
    "        elif i.collection_id == 'HLSL30.v2.0':\n",
    "            #print(i.properties['eo:cloud_cover'])\n",
    "            evi_bands = l30_bands\n",
    "\n",
    "        for a in i.assets:\n",
    "            if any(b==a for b in evi_bands):\n",
    "                evi_band_links.append(i.assets[a].href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-thunder",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(evi_band_links)/4    # Print the number of Items that match our cloud criteria "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-massachusetts",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### Split Data Links List into Logical Groupings\n",
    "Open Sentinel Hub.\n",
    "Select “Harmonized Landsat Sentinel” checkbox on the left, change the cloud cover slider to < 20%.\n",
    "\n",
    " Then you can find a region you want with different UTM tile.\n",
    "eg. s3://lp-prod-protected/HLSS30.020/HLS.S30.T10SEF.2024102T185919.v2.0, where UTM tile is 'T10SEF'and you want to split the links by the tiles you want.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-doubt",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "Split by Universal Transverse Mercator (UTM) tile specified in the file name (e.g., T11SLB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-chicago",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_dicts = defaultdict(list)    # https://stackoverflow.com/questions/26367812/appending-to-list-in-python-dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checked-microphone",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in evi_band_links:\n",
    "    tile = l.split('.')[-6]\n",
    "    tile_dicts[tile].append(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-feedback",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "#### Print dictionary keys and values, i.e. the data links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_dicts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-frank",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_dicts['T11SLB'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-restriction",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "Now we will create a seperate list of data links for each tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-small",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_links_T11SLC = tile_dicts['T11SLC']\n",
    "tile_links_T11SKC = tile_dicts['T11SKC']\n",
    "tile_links_T11SKB = tile_dicts['T11SKB']\n",
    "tile_links_T11SLB = tile_dicts['T11SLB']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-utility",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "#### Print band/layer links for HLS tile T11SLB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-pontiac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_links_T11SLB[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-corporation",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "#### Split the links by band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-hudson",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_dicts = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-picture",
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in tile_links_T11SLB:\n",
    "    band = b.split('.')[-2]\n",
    "    bands_dicts[band].append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-transport",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_dicts.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceramic-justice",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### Save links to a text file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phantom-indonesia",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "#### Write links from CMR-STAC API to a file\n",
    "We will generate two types of links: HTTPS and S3. HTTPS is a direct link to the NASA Earthdata data library, which you can input into your browser and download the .tif files manually. S3 links allow us to directly access Earthdata in code, avoiding the need to save the .tif files to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f8e976-5fc4-4d56-85da-18fe80e11d7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(bands_dicts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in bands_dicts.items():\n",
    "    name = (f'HTTPS_T11SLB_{k}_Links.txt')\n",
    "    with open(f'../data/{name}', 'w') as f:\n",
    "        for l in v:\n",
    "            f.write(f\"{l}\" + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-brush",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "#### Write links to file for S3 access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-cause",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in bands_dicts.items():\n",
    "    name = (f'S3_T11SLB_{k}_Links.txt')\n",
    "    with open(f'../data/{name}', 'w') as f:\n",
    "        for l in v:\n",
    "            s3l = l.replace('https://data.lpdaac.earthdatacloud.nasa.gov/', 's3://')\n",
    "            f.write(f\"{s3l}\" + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
